# 健康检查

#### 滚动更新
滚动更新是一次只更新一小部分副本，成功后，再更新更多的副本，最终完成所有副本的更新。滚动更新的最大的好处是零停机，整个更新过程始终有副本在运行，从而保证了业务的连续性。

下面我们部署三副本应用，初始镜像为 httpd:2.2.31，然后将其更新到 httpd:2.2.32。

```yaml
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: httpd
spec: 
  replicas: 3
  template:
    metadata:
      labels:
        run: httpd
    spec:
      containers:
      - name: httpd
        image: httpd:2.2.31
        ports:
        - containerPort: 80
```

部署过程: 
* 创建 Deployment httpd
* 创建 ReplicaSet httpd-***
* 创建三个 Pod
* 当前镜像为 httpd:2.2.31
![bbc14c60e3b8c18e98dad08d5cb8c0a3.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p3989)
查看replicaset 

kubectl get replicaset -o wide
![2f9995b75166ef466112e9081812d595.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p3990)

将配置文件中 httpd:2.2.31 替换为 httpd:2.2.32，再次执行 kubectl apply。


具体过程可以通过
kubectl describe deployment httpd查看
![a43d62f8a2061153a6336251a213314c.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p3991)

可以看到replicaset每次只更新替换一个 Pod：

每次替换的Pod数量是可以定制的,kubernetes可以提供两个参数maxSurge 和 maxUnavailable 来精细控制 Pod 的替换数量.


#### 回滚
kubectl apply 每次更新应用时 Kubernetes 都会记录下当前的配置，保存为一个 revision（版次），这样就可以回滚到某个特定 revision。

默认配置下,kubernets只会保留最近的几个 revision，可以在 Deployment 配置文件中通过 revisionHistoryLimit 属性增加 revision 数量。

下面实践回滚功能。应用有如下三个配置文件 httpd.v1.yml，httpd.v2.yml 和 httpd.v3.yml，分别对应不同的 httpd 镜像 2.2.31，2.2.32 和 2.4.18

![5b5de3b36b884cc02badf9c21ce3be6d.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p3992)
通过 kubectl apply 部署并更新应用：
![4855ff82c304c7e4cbbbe26aa054ab8e.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p3993)
--record 的作用是将当前命令记录到 revision 记录中，这样我们就可以知道每个 revison 对应的是哪个配置文件。通过 
kubectl rollout history deployment httpd 查看 revison 历史记录。

![e73445b65f6f0dc9896dde318fb0616e.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p3994)
CHANGE-CAUSE 就是 --record 的结果。如果要回滚到某个版本，比如 revision 1，可以执行命令 
```shell
kubectl rollout undo deployment httpd --to-revision=1：
```
![99b4653c05d744ccf25320cb2946843b.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p3995)
此时，revison 历史记录也会发生相应变化。
```shell
kubectl rollout history deployment httpd
```
![562607528703061a57a171b6282d5f43.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p3996)

revison 1 变成了 revison 4。不过我们可以通过 CHANGE-CAUSE 知道每个 revison 的具体含义。所以一定要在执行 kubectl apply 时加上 --record参数。

#### Health Check
强大的自愈能力是 Kubernetes 这类容器编排引擎的一个重要特性。自愈的默认实现方式是自动重启发生故障的容器。除此之外，用户还可以利用 Liveness 和 Readiness 探测机制设置更精细的健康检查，进而实现如下需求：

* 零停机部署。
* 避免部署无效的镜像。
* 更加安全的滚动升级。

##### 默认的健康检查
Kubernetes 默认的健康检查机制：

每个容器启动时都会执行一个进程，此进程由 Dockerfile 的 CMD 或 ENTRYPOINT 指定。如果进程退出时返回码非零，则认为容器发生故障，Kubernetes 就会根据 restartPolicy 重启容器。

下面我们模拟一个容器发生故障的场景，Pod 配置文件如下：

```yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: healthcheck
  name: healthcheck
spec:
  restartPolicy: OnFailure
  containers:
  - name: healthcheck
    image: busybox
    args: 
    - /bin/sh
    - -c
    - sleep 10; exit 1
```
过几分钟查看pod状态:

![70f87be1d2fb90f8bfd9362c36931fc6.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p3997)
可看到容器当前已经重启了 4 次。

在上面的例子中，容器进程返回值非零，Kubernetes 则认为容器发生故障，需要重启。但有不少情况是发生了故障，但进程并不会退出。比如访问 Web 服务器时显示 500 内部错误，可能是系统超载，也可能是资源死锁，此时 httpd 进程并没有异常退出，在这种情况下重启容器可能是最直接最有效的解决方案，那我们如何利用 Health Check 机制来处理这类场景呢？

##### liveness探测
Liveness 探测让用户可以自定义判断容器是否健康的条件。如果探测失败，Kubernetes 就会重启容器。

还是距离说明,创建如下pod:
```yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness
spec:
  restartPolicy: OnFailure
  containers:
  - name: liveness
    image: busybox
    args:
    - /bin/sh
    - -c
    - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600
    livenessProbe:
      exec:
        command:
        - cat
        - /tmp/healthy
      initialDelaySeconds: 30
      periodSeconds: 5
```
启动进程首先创建文件 /tmp/healthy，30 秒后删除，在我们的设定中，如果 /tmp/healthy 文件存在，则认为容器处于正常状态，反正则发生故障。

livenessProbe 部分定义如何执行 Liveness 探测：

探测的方法是：通过 cat 命令检查 /tmp/healthy 文件是否存在。如果命令执行成功，返回值为零，Kubernetes 则认为本次 Liveness 探测成功；如果命令返回值非零，本次 Liveness 探测失败。

initialDelaySeconds: 30 指定容器启动 30秒 之后开始执行 Liveness 探测，我们一般会根据应用启动的准备时间来设置。比如某个应用正常启动要花 30 秒，那么 initialDelaySeconds 的值就应该大于 30。

periodSeconds: 5 指定每 5 秒执行一次 Liveness 探测。Kubernetes 如果连续执行 3 次 Liveness 探测均失败，则会杀掉并重启容器。

下面创建 Pod liveness：
```shell
kubectl apply -f liveness.yml
```

从配置文件可知，最开始的 30 秒，/tmp/healthy 存在，cat 命令返回 0，Liveness 探测成功，这段时间 kubectl describe pod liveness 的 Events部分会显示正常的日志。
![35d9a8eede83e607d18e9c9b8aa17a8d.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p3999)
之后，日志会显示 /tmp/healthy 已经不存在，Liveness 探测失败。再过几十秒，几次探测都失败后，容器会被重启。

![d9087e926c73d55336554ecb9fb10780.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p3998)

除了 Liveness 探测，Kubernetes Health Check 机制还包括 Readiness 探测.

#### readiness探测
除了 Liveness 探测，Kubernetes Health Check 机制还包括 Readiness 探测。

用户通过 Liveness 探测可以告诉 Kubernetes 什么时候通过重启容器实现自愈；Readiness 探测则是告诉 Kubernetes 什么时候可以将容器加入到 Service 负载均衡池中，对外提供服务。

Readiness 探测的配置语法与 Liveness 探测完全一样，下面是个例子：
```yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: readiness
  name: readiness
spec:
  restartPolicy: OnFailure
  containers:
  - name: liveness
    image: busybox
    args:
    - /bin/sh
    - -c
    - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600
    readinessProbe:
      exec:
        command:
        - cat
        - /tmp/healthy
      initialDelaySeconds: 30
      periodSeconds: 5
```
这个配置文件只是将前面例子中的 liveness 替换为了 readiness，我们看看有什么不同的效果。
```shell
kubectl apply -f readiness.yml
```
![057f019432ce53e2fc7b91d84f5b3fdb.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p4000)

Pod readiness 的 READY 状态经历了如下变化：

刚被创建时，READY 状态为不可用。

15 秒后（initialDelaySeconds + periodSeconds），第一次进行 Readiness 探测并成功返回，设置 READY 为可用。

30 秒后，/tmp/healthy 被删除，连续 3 次 Readiness 探测均失败后，READY 被设置为不可用。

通过 kubectl describe pod readiness 也可以看到 Readiness 探测失败的日志。
![785e4cff49358a0b2d2c600b9aa8cadb.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p4001)


Liveness 探测和 Readiness 探测比较：

* Liveness 探测和 Readiness 探测是两种 Health Check 机制，如果不特意配置，Kubernetes 将对两种探测采取相同的默认行为，即通过判断容器启动进程的返回值是否为零来判断探测是否成功。

* 两种探测的配置方法完全一样，支持的配置参数也一样。不同之处在于探测失败后的行为：Liveness 探测是重启容器；Readiness 探测则是将容器设置为不可用，不接收 Service 转发的请求。

* Liveness 探测和 Readiness 探测是独立执行的，二者之间没有依赖，所以可以单独使用，也可以同时使用。用 Liveness 探测判断容器是否需要重启以实现自愈；用 Readiness 探测判断容器是否已经准备好对外提供服务。

#### 使用health check扩容
对于多副本应用，当执行 Scale Up 操作时，新副本会作为 backend 被添加到 Service 的负责均衡中，与已有副本一起处理客户的请求。考虑到应用启动通常都需要一个准备阶段，比如加载缓存数据，连接数据库等，从容器启动到能够提供服务是需要一段时间的。我们可以通过 Readiness 探测判断容器是否就绪，避免将请求发送到还没有 ready 的 backend。

下面是示例应用的配置文件。

```yaml
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: web
spec:
  replicas: 3
  template:
    metadata:
      labels:
        run: web
    spec:
      containers:
      - name: web
        image: myhttpd
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            scheme: HTTP
            path: /healthy
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5

---
apiVersion: v1
kind: service
metadata:
  name: web-svc
spec:
  selector:
    run: web
  ports:
  - protocol: TCP
    port: 8080
    targetPort: 80
```

重点关注 readinessProbe 部分。这里我们使用了不同于 exec 的另一种探测方法 -- httpGet。Kubernetes 对于该方法探测成功的判断条件是 http 请求的返回代码在 200-400 之间。

schema 指定协议，支持 HTTP（默认值）和 HTTPS。
path 指定访问路径。
port 指定端口。

上面配置的作用是：

* 容器启动 10 秒之后开始探测。

* 如果 http://[container_ip]:8080/healthy 返回代码不是 200-400，表示容器没有就绪，不接收 Service web-svc 的请求。

* 每隔 5 秒再探测一次。

* 直到返回代码为 200-400，表明容器已经就绪，然后将其加入到 web-svc 的负责均衡中，开始处理客户请求。

* 探测会继续以 5 秒的间隔执行，如果连续发生 3 次失败，容器又会从负载均衡中移除，直到下次探测成功重新加入。

对于 http://[container_ip]:8080/healthy，应用则可以实现自己的判断逻辑，比如检查所依赖的数据库是否就绪
![2464dd0e67cdb32b0bbbe6d5f1847088.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p4002)

① 定义 /healthy 的处理函数。

② 连接数据库并执行测试 SQL。

③ 测试成功，正常返回，代码 200。

④ 测试失败，返回错误代码 503。

⑤ 在 8080 端口监听。

对于生产环境中重要的应用都建议配置 Health Check，保证处理客户请求的容器都是准备就绪的 Service backend。


#### 回滚时使用健康检查
Health Check 另一个重要的应用场景是 Rolling Update。试想一下下面的情况：

现有一个正常运行的多副本应用，接下来对应用进行更新（比如使用更高版本的 image），Kubernetes 会启动新副本，然后发生了如下事件：
* 正常情况下新副本需要 10 秒钟完成准备工作，在此之前无法响应业务请求。
* 但由于人为配置错误，副本始终无法完成准备工作（比如无法连接后端数据库）。

先别继续，现在请花一分钟思考这个问题：如果没有配置 Health Check，会出现怎样的情况？

因为新副本本身没有异常退出，默认的 Health Check 机制会认为容器已经就绪，进而会逐步用新副本替换现有副本，其结果就是：当所有旧副本都被替换后，整个应用将无法处理请求，无法对外提供服务。如果这是发生在重要的生产系统上，后果会非常严重。

如果正确配置了 Health Check，新副本只有通过了 Readiness 探测，才会被添加到 Service；如果没有通过探测，现有副本不会被全部替换，业务仍然正常进行。

通过例子来实践 Health Check 在 Rolling Update 中的应用。



配置文件 app.v1.yml
```yaml
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: app
spec:
  replicas: 5
  template:
    metadata:
      labels:
        run: app
    spec:
      containers:
      - name: app
        image: busybox
        args:
        - /bin/sh
        - -c
        - sleep 10; touch /tmp/healthy; sleep 30000
        readinessProbe:
          exec:
            command:
            - cat
            - /tmp/healthy
          initialDelaySeconds: 30
          periodSeconds: 5
```

过 30秒后能够通过Readiness探测

![340e723ddcb0efd31a6b567c24563e5e.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p4003)

接下来滚动更新应用，配置文件 app.v2.yml 如下：

```shell
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: app
spec:
  replicas: 5
  template:
    metadata:
      labels:
        run: app
    spec:
      containers:
      - name: app
        image: busybox
        args:
        - /bin/sh
        - -c
        - sleep 30000
        readinessProbe:
          exec:
            command:
            - cat
            - /tmp/healthy
          initialDelaySeconds: 30
          periodSeconds: 5
```
很显然，由于新副本中不存在 /tmp/healthy，是无法通过 Readiness 探测的。验证如下：
```shell
kubectl apply -f app.v2.yml --record

kubectl get deployment app

kubectl get pod
```



这里一些docker版本可能出现bug      [dockerd终止bug](https://github.com/moby/moby/issues/36002)   ,bug信息如下:
```shell
transport: dial unix /var/run/docker/containerd/docker-containerd.sock: connect: connection refused"
```
出现此bug, 则需要killall -9 dockerd 或者类似的方式杀掉docker进程重启docker.



![8e1c7f7781cc3c13f9e677f029b89a1a.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p4005)

这个截图包含了大量的信息，值得我们详细分析。
先关注 kubectl get pod 输出：
从 Pod 的 AGE 栏可判断，最后 3 个 Pod 是新副本，目前处于 NOT READY 状态。

旧副本从最初 5 个减少到 4 个。

再来看 kubectl get deployment app 的输出：
![da98ac40cd25c9e5a975e7ab1bdeea99.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p4006)


UP-TO-DATE 3 表示当前已经完成更新的副本数：即 3 个新副本。

AVAILABLE 4 表示当前处于 READY 状态的副本数：即 4个旧副本。
在我们的设定中，新副本始终都无法通过 Readiness 探测，所以这个状态会一直保持下去。

上面我们模拟了一个滚动更新失败的场景。不过幸运的是：Health Check 帮我们屏蔽了有缺陷的副本，同时保留了大部分旧副本，业务没有因更新失败受到影响。

接下来我们要回答：为什么新创建的副本数是 3 个，同时只销毁了 1 个旧副本？

原因是：滚动更新通过参数 maxSurge 和 maxUnavailable 来控制副本替换的数量。

##### maxSurge
此参数控制滚动更新过程中副本总数的超过 DESIRED 的上限。maxSurge 可以是具体的整数（比如 3），也可以是百分百，向上取整。maxSurge 默认值为 25%。

在上面的例子中，DESIRED 为 5，那么副本总数的最大值为：
roundUp(5 + 5 * 25%) = 7

所以我们看到 CURRENT 就是 7。

##### maxUnavailable
此参数控制滚动更新过程中，不可用的副本相占 DESIRED 的最大比例。 maxUnavailable 可以是具体的整数（比如 3），也可以是百分百，向下取整。maxUnavailable 默认值为 25%。

在上面的例子中，DESIRED 为 10，那么可用的副本数至少要为：
5 - roundDown(10 * 25%) = 4

所以我们看到 AVAILABLE 就是 4。

maxSurge 值越大，初始创建的新副本数量就越多；maxUnavailable 值越大，初始销毁的旧副本数量就越多。

理想情况下，我们这个案例滚动更新的过程应该是这样的：

* 首先创建 3 个新副本使副本总数达到 7 个。
* 然后销毁 1 个旧副本使可用的副本数降到 3 个。
* 当新副本通过 Readiness 探测后，会使可用副本数增加，超过 4。
* 进而可以继续销毁更多的旧副本，使可用副本数回到 5。
* 旧副本的销毁使副本总数低于 7，这样就允许创建更多的新副本。
* 这个过程会持续进行，最终所有的旧副本都会被新副本替换，滚动更新完成。

而我们的实际情况是在第 4 步就卡住了，新副本无法通过 Readiness 探测。这个过程可以在 kubectl describe deployment app 的日志部分查看。
![4226a876fdd366511e3bd4293cb408a6.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p4008)



如果滚动更新失败，可以通过 kubectl rollout undo 回滚到上一个版本。
```shell
kubectl rollout history deployment app
kubectl rollout undo deployment app --to-revision=1
```
![73548586a64fa52fd4a09e935110fe59.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p4009)

之后,回滚到版本1
![6a8d434263c841ad7177815388c2a7f5.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p4010)
如果要定制 maxSurge 和 maxUnavailable，可以如下配置：
![d7819bdfa4dc89e7de357aa72b902651.png](evernotecid://8FFE4719-72F7-4332-B58A-CDD367D554D8/appyinxiangcom/18527455/ENResource/p4011)



小结: Kubernetes 健康检查的两种机制：Liveness 探测和 Readiness 探测，并实践了健康检查在 Scale Up 和 Rolling Update 场景中的应用。

